# ğŸ—ï¸ Proposed New Project Structure

## MAIN DIRECTORIES
```
amazon-discovery/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                    # Core functionality (keep existing)
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ data_objects.py
â”‚   â”‚   â”œâ”€â”€ detectors.py
â”‚   â”‚   â”œâ”€â”€ scoring.py
â”‚   â”‚   â”œâ”€â”€ visualizers.py
â”‚   â”‚   â””â”€â”€ processors.py
â”‚   â”œâ”€â”€ providers/               # Data providers (reorganized)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ usgs_provider.py     # (renamed from usgs_api.py)
â”‚   â”‚   â”œâ”€â”€ gee_provider.py
â”‚   â”‚   â””â”€â”€ sentinel2_provider.py # (future addition)
â”‚   â”œâ”€â”€ checkpoints/             # NEW: OpenAI checkpoint system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_checkpoint.py
â”‚   â”‚   â”œâ”€â”€ checkpoint1.py       # Familiarize + OpenAI test
â”‚   â”‚   â”œâ”€â”€ checkpoint2.py       # Early explorer
â”‚   â”‚   â”œâ”€â”€ checkpoint3.py       # Site discovery
â”‚   â”‚   â”œâ”€â”€ checkpoint4.py       # Story & impact
â”‚   â”‚   â””â”€â”€ checkpoint5.py       # Final submission
â”‚   â”œâ”€â”€ pipeline/                # Simplified pipeline (rename pipeline_steps/)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   â”œâ”€â”€ scoring.py
â”‚   â”‚   â”œâ”€â”€ reporting.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ drive_downloader.py
â”œâ”€â”€ main.py                      # Simplified entry point
â”œâ”€â”€ openai_checkpoints.py        # NEW: OpenAI checkpoint runner
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .env.template
â””â”€â”€ README.md
```

## KEY CHANGES

### 1. **Eliminate Dual Pipeline**
- Remove `ArchaeologicalPipeline` class from main.py
- Keep only `ModularPipeline` approach
- Simplify main.py to just CLI + checkpoint routing

### 2. **Add OpenAI Checkpoint System**
```python
# openai_checkpoints.py - NEW FILE
class CheckpointRunner:
    def run_checkpoint1(self):
        """Familiarize yourself with challenge and data"""
        # Download one LiDAR tile or Sentinel-2 scene
        # Run single OpenAI prompt
        # Print model version and dataset ID
        
    def run_checkpoint2(self):
        """Early explorer - multiple data types"""
        # Load two independent sources
        # Produce 5 anomaly footprints
        # Log all dataset IDs and prompts
        
    def run_checkpoint3(self):
        """New Site Discovery"""
        # Single best site with evidence
        # Algorithmic detection + historical cross-reference
        # Compare to known archaeological feature
        
    def run_checkpoint4(self):
        """Story & impact draft"""
        # Two-page PDF with cultural context
        # Hypotheses for function/age
        # Proposed survey effort
        
    def run_checkpoint5(self):
        """Final submission"""
        # Everything above + polish
        # Livestream-ready presentation
```

### 3. **Reorganize by Function**
- `src/core/` - Core archaeological algorithms
- `src/providers/` - Data providers (GEE, future Sentinel-2)
- `src/checkpoints/` - OpenAI competition checkpoints
- `src/pipeline/` - Modular pipeline steps
- `src/utils/` - Helper utilities

### 4. **Simplified main.py**
```python
# New simplified main.py
def main():
    parser = argparse.ArgumentParser()
    
    # OpenAI checkpoint options
    parser.add_argument('--checkpoint', type=int, choices=[1,2,3,4,5],
                       help='Run specific OpenAI checkpoint')
    
    # Regular pipeline options (simplified)
    parser.add_argument('--zones', nargs='+', help='Target zones')
    parser.add_argument('--provider', choices=['usgs', 'gee'], default='usgs')
    parser.add_argument('--full-pipeline', action='store_true')
    
    args = parser.parse_args()
    
    if args.checkpoint:
        from openai_checkpoints import CheckpointRunner
        runner = CheckpointRunner()
        runner.run(args.checkpoint)
    else:
        from src.pipeline.modular_pipeline import ModularPipeline
        pipeline = ModularPipeline(provider=args.provider)
        pipeline.run(zones=args.zones)

if __name__ == "__main__":
    main()
```

## MIGRATION STEPS

### Step 1: Create New Structure
1. Create `src/checkpoints/` directory
2. Create `openai_checkpoints.py`
3. Rename `src/pipeline_steps/` to `src/pipeline/`
4. Move providers to `src/providers/`

### Step 2: Implement Checkpoints
1. Build checkpoint base class
2. Implement each of the 5 OpenAI checkpoints
3. Add OpenAI API integration for text analysis

### Step 3: Simplify main.py
1. Remove `ArchaeologicalPipeline` class
2. Keep only CLI parsing + routing
3. Route to either checkpoints or modular pipeline

### Step 4: Test & Validate
1. Ensure all existing functionality works
2. Test checkpoint system
3. Verify OpenAI integration

## BENEFITS

1. **Competition Ready** - Matches OpenAI checkpoint structure exactly
2. **No Duplication** - Single pipeline approach
3. **Better Organization** - Clear separation by function
4. **Easier Extension** - Add new providers/checkpoints easily
5. **Maintainable** - Smaller, focused files